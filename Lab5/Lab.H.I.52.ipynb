{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
    "# Use watsonx, and `mistralai/mistral-large` to make simple chat conversation and tool calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Disclaimers\n",
    "\n",
    "- Use only Projects and Spaces that are available in watsonx context.\n",
    "\n",
    "\n",
    "## Notebook content\n",
    "\n",
    "This notebook provides a detailed demonstration of the steps and code required to showcase support for Chat models, including the integration of tools and watsonx.ai models.\n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses Python 3.11.\n",
    "\n",
    "\n",
    "## Learning goal\n",
    "\n",
    "The purpose of this notebook is to demonstrate how to use Chat models, e.g. `mistralai/mistral-large` by using tools.\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "This notebook contains the following parts:\n",
    "\n",
    "- [Setup](#setup)\n",
    "- [Foundation Models on watsonx](#models)\n",
    "- [Work with chat messages](#chat)\n",
    "- [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"setup\"></a>\n",
    "## Set up the environment\n",
    "\n",
    "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
    "\n",
    "-  Create a <a href=\"https://cloud.ibm.com/catalog/services/watsonxai-runtime\" target=\"_blank\" rel=\"noopener no referrer\">watsonx.ai Runtime Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/wml-plans.html?context=wx&audience=wdp\" target=\"_blank\" rel=\"noopener no referrer\">here</a>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Install and import the `datasets` and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-11-24T09:07:07.614367Z",
     "start_time": "2025-11-24T09:07:01.206322Z"
    }
   },
   "source": "!uv pip install -U \"langchain_ibm>=0.3,<0.4\"",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2mUsing Python 3.12.12 environment at: C:\\Users\\koste\\Desktop\\UW\\Arbitraz\\.venv\u001B[0m\n",
      "\u001B[2mResolved \u001B[1m40 packages\u001B[0m \u001B[2min 875ms\u001B[0m\u001B[0m\n",
      "\u001B[2mPrepared \u001B[1m14 packages\u001B[0m \u001B[2min 2.54s\u001B[0m\u001B[0m\n",
      "\u001B[2mUninstalled \u001B[1m6 packages\u001B[0m \u001B[2min 1.00s\u001B[0m\u001B[0m\n",
      "\u001B[2mInstalled \u001B[1m14 packages\u001B[0m \u001B[2min 1.55s\u001B[0m\u001B[0m\n",
      " \u001B[31m-\u001B[39m \u001B[1mcachetools\u001B[0m\u001B[2m==6.2.1\u001B[0m\n",
      " \u001B[32m+\u001B[39m \u001B[1mcachetools\u001B[0m\u001B[2m==6.2.2\u001B[0m\n",
      " \u001B[31m-\u001B[39m \u001B[1mcertifi\u001B[0m\u001B[2m==2025.10.5\u001B[0m\n",
      " \u001B[32m+\u001B[39m \u001B[1mcertifi\u001B[0m\u001B[2m==2025.11.12\u001B[0m\n",
      " \u001B[31m-\u001B[39m \u001B[1mibm-watsonx-ai\u001B[0m\u001B[2m==1.4.2\u001B[0m\n",
      " \u001B[32m+\u001B[39m \u001B[1mibm-watsonx-ai\u001B[0m\u001B[2m==1.4.7\u001B[0m\n",
      " \u001B[32m+\u001B[39m \u001B[1mjsonpatch\u001B[0m\u001B[2m==1.33\u001B[0m\n",
      " \u001B[32m+\u001B[39m \u001B[1mlangchain-core\u001B[0m\u001B[2m==0.3.80\u001B[0m\n",
      " \u001B[32m+\u001B[39m \u001B[1mlangchain-ibm\u001B[0m\u001B[2m==0.3.20\u001B[0m\n",
      " \u001B[32m+\u001B[39m \u001B[1mlangsmith\u001B[0m\u001B[2m==0.4.46\u001B[0m\n",
      " \u001B[31m-\u001B[39m \u001B[1mnumpy\u001B[0m\u001B[2m==1.26.4\u001B[0m\n",
      " \u001B[32m+\u001B[39m \u001B[1mnumpy\u001B[0m\u001B[2m==2.3.5\u001B[0m\n",
      " \u001B[32m+\u001B[39m \u001B[1morjson\u001B[0m\u001B[2m==3.11.4\u001B[0m\n",
      " \u001B[31m-\u001B[39m \u001B[1mpydantic\u001B[0m\u001B[2m==2.12.3\u001B[0m\n",
      " \u001B[32m+\u001B[39m \u001B[1mpydantic\u001B[0m\u001B[2m==2.12.4\u001B[0m\n",
      " \u001B[31m-\u001B[39m \u001B[1mpydantic-core\u001B[0m\u001B[2m==2.41.4\u001B[0m\n",
      " \u001B[32m+\u001B[39m \u001B[1mpydantic-core\u001B[0m\u001B[2m==2.41.5\u001B[0m\n",
      " \u001B[32m+\u001B[39m \u001B[1mrequests-toolbelt\u001B[0m\u001B[2m==1.0.0\u001B[0m\n",
      " \u001B[32m+\u001B[39m \u001B[1mtenacity\u001B[0m\u001B[2m==9.1.2\u001B[0m\n",
      " \u001B[32m+\u001B[39m \u001B[1mzstandard\u001B[0m\u001B[2m==0.25.0\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Define the watsonx.ai credentials\n",
    "Use the code cell below to define the watsonx.ai credentials that are required to work with watsonx Foundation Model inferencing.\n",
    "\n",
    "**Action:** Provide the IBM Cloud user API key. For details, see <a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\" rel=\"noopener no referrer\">Managing user API keys</a>."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-11-24T09:07:40.890818Z",
     "start_time": "2025-11-24T09:07:26.709129Z"
    }
   },
   "source": [
    "import getpass\n",
    "from ibm_watsonx_ai import Credentials\n",
    "\n",
    "credentials = Credentials(\n",
    "    url=\"https://eu-gb.ml.cloud.ibm.com\",\n",
    "    api_key=getpass.getpass(\"Enter your watsonx.ai api key and hit enter: \"),\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Define the project ID\n",
    "You need to provide the project ID to give the Foundation Model the context for the call. If you have a default project ID set in Watson Studio, the notebook obtains that project ID. Otherwise, you need to provide the project ID in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-11-24T09:07:55.667318Z",
     "start_time": "2025-11-24T09:07:47.837351Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    project_id = os.environ[\"PROJECT_ID\"]\n",
    "except KeyError:\n",
    "    project_id = input(\"Enter your project_id and hit enter: \")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"models\"></a>\n",
    "## Set up the Foundation Model on `watsonx.ai`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the `model_id` of the model you will use for the chat with tools."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T09:11:59.013838Z",
     "start_time": "2025-11-24T09:11:58.201977Z"
    }
   },
   "source": [
    "from ibm_watsonx_ai import Credentials, APIClient\n",
    "client = APIClient(credentials, project_id)\n",
    "\n",
    "for model in client.foundation_models.get_model_specs()['resources']:\n",
    "    print(model[\"model_id\"])\n",
    "\n",
    "model_id = \"ibm/granite-3-8b-instruct\"\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-encoder/ms-marco-minilm-l-12-v2\n",
      "ibm/granite-3-8b-instruct\n",
      "ibm/granite-embedding-278m-multilingual\n",
      "ibm/granite-ttm-1024-96-r2\n",
      "ibm/granite-ttm-1536-96-r2\n",
      "ibm/granite-ttm-512-96-r2\n",
      "ibm/slate-125m-english-rtrvr-v2\n",
      "ibm/slate-30m-english-rtrvr-v2\n",
      "intfloat/multilingual-e5-large\n",
      "meta-llama/llama-3-2-11b-vision-instruct\n",
      "meta-llama/llama-3-3-70b-instruct\n",
      "meta-llama/llama-4-maverick-17b-128e-instruct-fp8\n",
      "mistralai/mistral-small-3-1-24b-instruct-2503\n",
      "sentence-transformers/all-minilm-l6-v2\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model parameters\n",
    "\n",
    "You might need to adjust model `parameters` depending on the model you use."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T09:12:38.394373Z",
     "start_time": "2025-11-24T09:12:36.815047Z"
    }
   },
   "source": [
    "from ibm_watsonx_ai.foundation_models.schema import TextChatParameters\n",
    "\n",
    "TextChatParameters.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| PARAMETER             | TYPE                                   | EXAMPLE VALUE                                                                                                                                                                                                                                                                   |\n",
      "+=======================+========================================+=================================================================================================================================================================================================================================================================================+\n",
      "| frequency_penalty     | float, NoneType                        | 0.5                                                                                                                                                                                                                                                                             |\n",
      "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| logprobs              | bool, NoneType                         | True                                                                                                                                                                                                                                                                            |\n",
      "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| top_logprobs          | int, NoneType                          | 3                                                                                                                                                                                                                                                                               |\n",
      "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| presence_penalty      | float, NoneType                        | 0.3                                                                                                                                                                                                                                                                             |\n",
      "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| response_format       | dict, TextChatResponseFormat, NoneType | {'type': 'json_schema', 'json_schema': {'name': 'Sample JSON schema', 'schema': {'title': 'SimpleUser', 'type': 'object', 'properties': {'username': {'type': 'string'}, 'email': {'type': 'string', 'format': 'email'}}, 'required': ['username', 'email']}, 'strict': False}} |\n",
      "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| temperature           | float, NoneType                        | 0.7                                                                                                                                                                                                                                                                             |\n",
      "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| max_tokens            | int, NoneType                          | N/A                                                                                                                                                                                                                                                                             |\n",
      "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| max_completion_tokens | int, NoneType                          | 512                                                                                                                                                                                                                                                                             |\n",
      "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| time_limit            | int, NoneType                          | 600000                                                                                                                                                                                                                                                                          |\n",
      "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| top_p                 | float, NoneType                        | 0.9                                                                                                                                                                                                                                                                             |\n",
      "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| n                     | int, NoneType                          | 1                                                                                                                                                                                                                                                                               |\n",
      "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| logit_bias            | dict, NoneType                         | {'1003': -100, '1004': -100}                                                                                                                                                                                                                                                    |\n",
      "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| seed                  | int, NoneType                          | 41                                                                                                                                                                                                                                                                              |\n",
      "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| stop                  | list, NoneType                         | ['this', 'the']                                                                                                                                                                                                                                                                 |\n",
      "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| guided_choice         | list, NoneType                         | ['red', 'blue']                                                                                                                                                                                                                                                                 |\n",
      "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| guided_regex          | str, NoneType                          | \\w+@\\w+\\.xai                                                                                                                                                                                                                                                                    |\n",
      "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| guided_grammar        | str, NoneType                          | root ::= rating \" stars\"                                                                                                                                                                                                                                                        |\n",
      "|                       |                                        | rating ::= [1-5]                                                                                                                                                                                                                                                                |\n",
      "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| guided_json           | dict, NoneType                         | {'type': 'object', 'properties': {'sentiment': {'type': 'string'}}}                                                                                                                                                                                                             |\n",
      "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| chat_template_kwargs  | dict, NoneType                         | {'thinking': True}                                                                                                                                                                                                                                                              |\n",
      "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| reasoning_effort      | Literal, NoneType                      | high                                                                                                                                                                                                                                                                            |\n",
      "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| include_reasoning     | bool, NoneType                         | True                                                                                                                                                                                                                                                                            |\n",
      "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| repetition_penalty    | float, NoneType                        | 1.5                                                                                                                                                                                                                                                                             |\n",
      "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| length_penalty        | float, NoneType                        | 1.0                                                                                                                                                                                                                                                                             |\n",
      "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T09:12:41.256954Z",
     "start_time": "2025-11-24T09:12:41.252539Z"
    }
   },
   "source": [
    "params = TextChatParameters(\n",
    "    temperature=1\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model\n",
    "\n",
    "Initialize the `ModelInference` class with the previously set parameters."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T09:12:54.561912Z",
     "start_time": "2025-11-24T09:12:53.745729Z"
    }
   },
   "source": [
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "\n",
    "model = ModelInference(\n",
    "    model_id=model_id,\n",
    "    credentials=credentials,\n",
    "    project_id=project_id,\n",
    "    params=params\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"chat\"></a>\n",
    "## Work with chat messages "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work with a simple chat message"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T09:13:00.092915Z",
     "start_time": "2025-11-24T09:12:59.248792Z"
    }
   },
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"What is 1 + 1\"\n",
    "    }\n",
    "]\n",
    "\n",
    "simple_chat_response = model.chat(messages=messages)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T09:13:04.160131Z",
     "start_time": "2025-11-24T09:13:04.154745Z"
    }
   },
   "source": [
    "print(simple_chat_response[\"choices\"][0][\"message\"][\"content\"])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|python_start|>def add(a, b):\n",
      "    return a + b\n",
      "\n",
      "result = add(1, 1)\n",
      "print(result)<|python_end|>\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work with a simple chat message using chat_stream"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T09:13:57.607451Z",
     "start_time": "2025-11-24T09:13:57.591068Z"
    }
   },
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"What IBM mainly does?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "simple_chat_stream_response = model.chat_stream(messages=messages)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T09:14:00.224509Z",
     "start_time": "2025-11-24T09:13:58.819138Z"
    }
   },
   "source": [
    "for chunk in simple_chat_stream_response:\n",
    "    print(chunk[\"choices\"][0][\"delta\"].get(\"content\", \"\"), end=\"\", flush=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|python_start|>tool_call(function_name=\"get_company_info\", args={\"company_name\": \"IBM\"})<|python_end|>"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIndexError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m simple_chat_stream_response:\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[43mchunk\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mchoices\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m[\u001B[33m\"\u001B[39m\u001B[33mdelta\u001B[39m\u001B[33m\"\u001B[39m].get(\u001B[33m\"\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m), end=\u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m, flush=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[31mIndexError\u001B[39m: list index out of range"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work with an advanced chat message"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T09:14:05.287175Z",
     "start_time": "2025-11-24T09:14:04.062349Z"
    }
   },
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Who won the world series in 2020?\"\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Where was it played?\"\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "advanced_chat_response = model.chat(messages=messages)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T09:14:07.937975Z",
     "start_time": "2025-11-24T09:14:07.933532Z"
    }
   },
   "source": [
    "print(advanced_chat_response[\"choices\"][0][\"message\"][\"content\"])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2020 World Series was played at Globe Life Field in Arlington, Texas. The series was between the Los Angeles Dodgers and the Tampa Bay Rays. The Dodgers won the series 4 games to 2. Globe Life Field was the home stadium of the Texas Rangers, but it was used as a neutral site due to COVID-19 pandemic restrictions.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work with chat messages using `tools` and `tool_choice`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T09:14:31.413739Z",
     "start_time": "2025-11-24T09:14:31.407135Z"
    }
   },
   "source": [
    "def get_current_weather(location: str, unit: str = \"celsius\") -> dict:\n",
    "    \"\"\"\n",
    "    Get the current weather in a given location.\n",
    "\n",
    "    Parameters:\n",
    "    - location (str): The city and state, e.g., \"San Francisco, CA\".\n",
    "    - unit (str): The unit for temperature, either \"celsius\" or \"fahrenheit\". Defaults to \"celsius\".\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary containing the current weather details.\n",
    "    \"\"\"\n",
    "    weather_data = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": 20,\n",
    "        \"unit\": unit,\n",
    "        \"description\": \"Partly cloudy\"\n",
    "    }\n",
    "    return weather_data"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting raw python function to correct tool schema"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T09:14:35.492637Z",
     "start_time": "2025-11-24T09:14:33.903357Z"
    }
   },
   "source": [
    "import json\n",
    "from langchain_ibm.chat_models import convert_to_openai_tool\n",
    "\n",
    "formatted_tools = [convert_to_openai_tool(get_current_weather)]\n",
    "print(json.dumps(formatted_tools, indent=4))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"type\": \"function\",\n",
      "        \"function\": {\n",
      "            \"name\": \"get_current_weather\",\n",
      "            \"description\": \"Get the current weather in a given location. Parameters:\\n- location (str): The city and state, e.g., \\\"San Francisco, CA\\\".\\n- unit (str): The unit for temperature, either \\\"celsius\\\" or \\\"fahrenheit\\\". Defaults to \\\"celsius\\\".\",\n",
      "            \"parameters\": {\n",
      "                \"properties\": {\n",
      "                    \"location\": {\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    \"unit\": {\n",
      "                        \"default\": \"celsius\",\n",
      "                        \"type\": \"string\"\n",
      "                    }\n",
      "                },\n",
      "                \"required\": [\n",
      "                    \"location\"\n",
      "                ],\n",
      "                \"type\": \"object\"\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T09:14:39.478901Z",
     "start_time": "2025-11-24T09:14:38.896722Z"
    }
   },
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather like in Boston today?\"},\n",
    "]\n",
    "\n",
    "tool_choice = {\"type\": \"function\", \"function\": {\"name\": \"get_current_weather\"}}\n",
    "\n",
    "tool_response = model.chat(messages=messages, tools=formatted_tools, tool_choice=tool_choice)"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T09:14:43.104168Z",
     "start_time": "2025-11-24T09:14:43.099716Z"
    }
   },
   "source": [
    "print(json.dumps(tool_response[\"choices\"][0][\"message\"], indent=4))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"\",\n",
      "    \"tool_calls\": [\n",
      "        {\n",
      "            \"id\": \"chatcmpl-tool-15cd8a04f9744d558d7512de693579b4\",\n",
      "            \"type\": \"function\",\n",
      "            \"function\": {\n",
      "                \"name\": \"get_current_weather\",\n",
      "                \"arguments\": \"{\\\"location\\\": \\\"Boston, MA\\\", \\\"unit\\\": \\\"fahrenheit\\\"}\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work with chat messages using `tools` and `tool_choice_option`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T09:14:45.756778Z",
     "start_time": "2025-11-24T09:14:45.751748Z"
    }
   },
   "source": [
    "def add_numbers(a: float, b: float) -> float:\n",
    "    \"\"\"\n",
    "    Adds two numbers.\n",
    "\n",
    "    Parameters:\n",
    "    - a (float): The first number.\n",
    "    - b (float): The second number.\n",
    "\n",
    "    Returns:\n",
    "    - float: The result of a + b.\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def multiply_numbers(a: float, b: float) -> float:\n",
    "    \"\"\"\n",
    "    Multiplies two numbers.\n",
    "\n",
    "    Parameters:\n",
    "    - a (float): The first number.\n",
    "    - b (float): The second number.\n",
    "\n",
    "    Returns:\n",
    "    - float: The result of a * b.\n",
    "    \"\"\"\n",
    "    return a * b"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting raw python function to correct tool schema"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T09:14:50.468135Z",
     "start_time": "2025-11-24T09:14:50.456174Z"
    }
   },
   "source": [
    "tool_choice_option = \"auto\"\n",
    "\n",
    "formatted_tools = [convert_to_openai_tool(tool) for tool in [add_numbers, multiply_numbers]]\n",
    "\n",
    "print(json.dumps(formatted_tools, indent=4))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"type\": \"function\",\n",
      "        \"function\": {\n",
      "            \"name\": \"add_numbers\",\n",
      "            \"description\": \"Adds two numbers. Parameters:\\n- a (float): The first number.\\n- b (float): The second number.\",\n",
      "            \"parameters\": {\n",
      "                \"properties\": {\n",
      "                    \"a\": {\n",
      "                        \"type\": \"number\"\n",
      "                    },\n",
      "                    \"b\": {\n",
      "                        \"type\": \"number\"\n",
      "                    }\n",
      "                },\n",
      "                \"required\": [\n",
      "                    \"a\",\n",
      "                    \"b\"\n",
      "                ],\n",
      "                \"type\": \"object\"\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"type\": \"function\",\n",
      "        \"function\": {\n",
      "            \"name\": \"multiply_numbers\",\n",
      "            \"description\": \"Multiplies two numbers. Parameters:\\n- a (float): The first number.\\n- b (float): The second number.\",\n",
      "            \"parameters\": {\n",
      "                \"properties\": {\n",
      "                    \"a\": {\n",
      "                        \"type\": \"number\"\n",
      "                    },\n",
      "                    \"b\": {\n",
      "                        \"type\": \"number\"\n",
      "                    }\n",
      "                },\n",
      "                \"required\": [\n",
      "                    \"a\",\n",
      "                    \"b\"\n",
      "                ],\n",
      "                \"type\": \"object\"\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T09:14:58.777591Z",
     "start_time": "2025-11-24T09:14:58.190160Z"
    }
   },
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is 5 + 6?\"},\n",
    "]\n",
    "\n",
    "tools_response = model.chat(messages=messages, tools=formatted_tools, tool_choice_option=tool_choice_option)\n",
    "\n",
    "print(json.dumps(tools_response[\"choices\"][0][\"message\"], indent=4))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"role\": \"assistant\",\n",
      "    \"tool_calls\": [\n",
      "        {\n",
      "            \"id\": \"chatcmpl-tool-5da24e84fd39479a892e67c01271031a\",\n",
      "            \"type\": \"function\",\n",
      "            \"function\": {\n",
      "                \"name\": \"add_numbers\",\n",
      "                \"arguments\": \"{\\\"a\\\": 5, \\\"b\\\": 6}\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T09:15:08.415650Z",
     "start_time": "2025-11-24T09:15:07.737287Z"
    }
   },
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is 5 * 6?\"},\n",
    "]\n",
    "\n",
    "tools_response_2 = model.chat(messages=messages, tools=formatted_tools, tool_choice_option=tool_choice_option)\n",
    "\n",
    "print(json.dumps(tools_response_2[\"choices\"][0][\"message\"], indent=4))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"role\": \"assistant\",\n",
      "    \"tool_calls\": [\n",
      "        {\n",
      "            \"id\": \"chatcmpl-tool-b60215a7fda94f9ba14be436dce804a9\",\n",
      "            \"type\": \"function\",\n",
      "            \"function\": {\n",
      "                \"name\": \"multiply_numbers\",\n",
      "                \"arguments\": \"{\\\"a\\\": 5, \\\"b\\\": 6}\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute tool calls\n",
    "\n",
    "We organize the two functions into a dictionary where keys represent the function name, and values are the function."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T09:15:11.378742Z",
     "start_time": "2025-11-24T09:15:11.374673Z"
    }
   },
   "source": [
    "names_to_functions = {\n",
    "    \"add_numbers\": add_numbers,\n",
    "    \"multiply_numbers\": multiply_numbers,\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T09:15:13.137024Z",
     "start_time": "2025-11-24T09:15:13.129433Z"
    }
   },
   "source": [
    "tool_call = tools_response[\"choices\"][0][\"message\"][\"tool_calls\"]\n",
    "function_name = tool_call[0][\"function\"][\"name\"]\n",
    "function_params = json.loads(tool_call[0][\"function\"][\"arguments\"])\n",
    "print(f\"Executing function: `{function_name}`, with parameters: {function_params}\")\n",
    "\n",
    "function_result = names_to_functions[function_name](**function_params)\n",
    "print(f\"Function result: {function_result}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing function: `add_numbers`, with parameters: {'a': 5, 'b': 6}\n",
      "Function result: 11\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T09:15:20.750285Z",
     "start_time": "2025-11-24T09:15:20.744097Z"
    }
   },
   "source": [
    "tool_call = tools_response_2[\"choices\"][0][\"message\"][\"tool_calls\"]\n",
    "function_name = tool_call[0][\"function\"][\"name\"]\n",
    "function_params = json.loads(tool_call[0][\"function\"][\"arguments\"])\n",
    "print(f\"Executing function: `{function_name}`, with parameters: {function_params}\")\n",
    "\n",
    "\n",
    "function_result = names_to_functions[function_name](**function_params)\n",
    "print(f\"Function result: {function_result}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing function: `multiply_numbers`, with parameters: {'a': 5, 'b': 6}\n",
      "Function result: 30\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"summary\"></a>\n",
    "## Summary and next steps\n",
    "\n",
    "You successfully completed this notebook!\n",
    "\n",
    "You learned how to work with chat models using tools and watsonx.ai.\n",
    "\n",
    "Check out our _<a href=\"https://ibm.github.io/watsonx-ai-python-sdk/samples.html\" target=\"_blank\" rel=\"noopener no referrer\">Online Documentation</a>_ for more samples, tutorials, documentation, how-tos, and blog posts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Author\n",
    "\n",
    "**Mateusz Szewczyk**, Software Engineer at watsonx.ai."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright Â© 2024-2025 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
